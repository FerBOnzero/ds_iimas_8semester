{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875c543-6344-4aeb-ae3a-de4a8823a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, List, Dict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24615be4-dd41-4348-afd2-4a01a9becea8",
   "metadata": {},
   "source": [
    "# 1. Funciones de Activación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c8b87-9831-4540-bbfb-c7bcf18ccb06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Implementar Funciones de Activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746ece3-e0f7-4c5e-8c59-ceceb5a7933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evalua utilizando la función sigmoide los puntos x.\n",
    "    :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "    :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "    \"\"\"\n",
    "    # TODO: Completa la función\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552bbbcc-50b3-4e36-9491-d57e47a03e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "plt.plot(x, sigmoid(x))\n",
    "plt.title(\"Función de Activación Sigmoide\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"σ(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964e72f-010d-46e6-90f2-3400608eb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evalua utilizando la función tangente hiperbólica los puntos x.\n",
    "    :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "    :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "    \"\"\"\n",
    "    # TODO: Completa la función.\n",
    "    # NOTA: No utilices la función np.tanh de NumPy.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2da45d-fbcc-4acd-beab-328810907c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, tanh(x))\n",
    "plt.title(\"Función de Activación Tanh\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"tanh(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15068d-d486-4578-b0ac-144573e50eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evalua utilizando la función ReLU los puntos x.\n",
    "    :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "    :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "    \"\"\"\n",
    "    # TODO: Completa la función.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c72117-abdf-4f69-8900-427501057bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, relu(x))\n",
    "plt.title(\"Función de Activación ReLU\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ReLU(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb9a56-63b8-4023-bd5a-0a2dfb80bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evalua utilizando la función softmax los puntos x.\n",
    "    :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "    :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "    \"\"\"\n",
    "    # TODO: Completa la función.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c1110-962f-4b76-a0cc-12ed7e216c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.5, 2.0, 0.1, 1.5])\n",
    "plt.bar(range(len(x)), softmax(x))\n",
    "plt.title(\"Función de Activación Softmax\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Probabilidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5be53-655d-4bb9-805c-44c302c5f493",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2 Implementar Derivadas de Funciones de Activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fca0e8-c762-439a-9a3d-d49314ba4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evalua los puntos x utilizando la derivada de la función sigmoide.\n",
    "    :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "    :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "    \"\"\"\n",
    "    # TODO: Completa la función\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e249e8-2c8e-40c7-a387-4ec93dddaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "plt.plot(x, sigmoid_derivative(x))\n",
    "plt.title(\"Derivada de Función Sigmoide\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"σ'(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dd0a8-9241-4ecc-a476-9e156515edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_derivative(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evalua los puntos x utilizando la derivada de la función tangente hiperbólica.\n",
    "    :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "    :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "    \"\"\"\n",
    "    # TODO: Completa la función.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fce838-7a18-4006-a163-93e2659233e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, tanh_derivative(x))\n",
    "plt.title(\"Derivada de la Función Tangente Hiperbólicda\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"tanh'(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa6219-ec81-45b2-b8a8-fb14157b9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evalua los puntos x utilizando la derivada de la función ReLU.\n",
    "    :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "    :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "    \"\"\"\n",
    "    # TODO: Completa la función.\n",
    "    # NOTA: Puedes usar la función np.where\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c4553-4b0a-4391-88c4-7459156e9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, relu_derivative(x))\n",
    "plt.title(\"Derivada de Función ReLU\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ReLU'(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809fc6b-dee4-41f6-88b6-f73bb2b0a584",
   "metadata": {},
   "source": [
    "# 2. Implementación de Red Neuronal Artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5ecc9-8e70-41d6-b58e-36cea04ec7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNeuralNetwork:\n",
    "    def __init__(self, layers, activation_func: Literal[\"relu\", \"sigmoid\", \"tanh\"]='relu') -> None:\n",
    "        \"\"\"\n",
    "        :param layers: Las capas de la red neuronal. La primera capa representa es la capa de entrada\n",
    "            y la última es la capa de salida.\n",
    "        :param activation_func: Función de activación a utilizar en todas las capas excepto en la de\n",
    "            salida.\n",
    "        \"\"\"\n",
    "        self._weights = []\n",
    "        self._biases = []\n",
    "        self._activation_func = activation_func\n",
    "        # TODO: Inicializa las matrices de pesos y vectores de sesgos utilizando \n",
    "        #     np.random.randn. Agrega en orden las matrices a los vectores a self._weights\n",
    "        #     y a self._biases.\n",
    "\n",
    "    def _activation(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Aplica la función de activación configurada.\n",
    "        :param x: Arreglo de NumPy de dimensiones (N,). Representa los puntos a evaluar.\n",
    "        :return: Arreglo de NumPy de dimensiones (N,). Contiene la evaluación de la función.\n",
    "        :raises ValueError: Cuando la función de activación no está soportada.\n",
    "        \"\"\"\n",
    "        # TODO: Completa la función siguiendo su docstring.\n",
    "        ...\n",
    "\n",
    "    def forward_propagation(self, x: np.ndarray) -> Tuple[float, List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"Propagación hacia adelante de la neurona.\n",
    "        :param x: Datos de entrada a propagar.\n",
    "        :return: Una tupla con 3 elementos. El primero la salida de la neurona, el segundo la lista\n",
    "            de activaciones y el tercero la lista de estados ocultos. Estos tres elementos se usarán\n",
    "            en la retropropagación para el cómputo de los gradientes.\n",
    "        \"\"\"\n",
    "        # TODO: Realiza la propagación hacia adelante de la neurona. \n",
    "        # NOTA: Recuerda que no debes de aplicar la función de activación en la última capa.\n",
    "        ...\n",
    "\n",
    "    def gradient_computation(\n",
    "        self,\n",
    "        output: float,\n",
    "        target: float,\n",
    "        x: np.ndarray,\n",
    "        activations: List[np.ndarray],\n",
    "        hidden_states: List[np.ndarray]\n",
    "    ) -> Dict[str, List[np.ndarray]]:\n",
    "        \"\"\"Calcula los gradientes para actualizar los pesos.\n",
    "        :param output: Salida de la propagación hacia adelante.\n",
    "        :param target: Valor objetivo o real a estimar.\n",
    "        :param x: Datos de entrada con los que se propagó la red.\n",
    "        :param activations: Activaciones resultado de la propagación hacia adelante.\n",
    "        :param hidden_states: Estados ocultos resultado de la propagación hacia adelante.\n",
    "        :return: Un diccionario con dos llaves 'weights' y 'biases'. El valor de cada una listas\n",
    "            de estas es un arreglo de NumPy que contienen los gradientes de los pesos y los sesgos\n",
    "            respectivamente.\n",
    "        \"\"\"\n",
    "        # TODO: Completa la función\n",
    "\n",
    "        # PASO 1: Inicializa el diccionario con los gradientes a utilizar.\n",
    "        # NOTA: Utiliza np.zeros_like para inicializar los gradientes.\n",
    "        gradients = ...\n",
    "\n",
    "        # PASO 2: Calcula la derivada del ECM con respecto a la salida de la red.\n",
    "        # NOTA: Recuerda que es para un solo punto i.e. n=1\n",
    "        loss_derivative = ...\n",
    "\n",
    "        # PASO 3: Actualiza los gradientes de la última capa\n",
    "        gradients[\"weights\"][-1] = ...\n",
    "        gradients[\"biases\"][-1] = ...\n",
    "\n",
    "        # Paso 4: Calcula los gradientes para el resto de las capas.\n",
    "        # Itera en un ciclo for para el resto de las capas. En cada iteración:\n",
    "        #     - Calcula el gradiente de h.\n",
    "        #     - Calcula el gradiente de a. (Utiliza las derivadas de las funciones de activación que programaste).\n",
    "        #     - Calcula el gradiente de w. (Recuerda utilizar x en lugar del estado oculto para la primera capa)\n",
    "        #     - Actualiza el diccionario de gradientes.\n",
    "        return gradients\n",
    "\n",
    "\n",
    "# Ejemplo de uso:\n",
    "nn = FullyConnectedNeuralNetwork(layers=[3, 5, 1], activation_func='relu')\n",
    "input_data = np.random.randn(3, 1)  # Ejemplo de entrada\n",
    "output = nn.forward_propagation(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15e581-d847-424e-b2e3-6a7afe419eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
